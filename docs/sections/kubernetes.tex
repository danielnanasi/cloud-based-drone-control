\chapter{Kialakított Kubernetes alapú felhő}

Ebben a fejezetben rátérünk a felhőrendszer tényleges megvalósítására. A \ref{cha:cloud}. fejezetben megnéztük milyen lehetséges mai technológiák közül választhatunk, realizálhattuk, hogy a Kubernetes tűnik a legjobb választásnak ilyen célra, most pedig ezen a vonalon haladunk tovább. Megnézzük Kubernetesen belül milyen lehetőségek vannak, mik a probléma alapfeltételei és hogyan lehet integrálni a \ref{cha:fizikai}. fejezetben bemutatott konténerkollaborációt egy ilyen Kubernetes felhőbe.

\section{Kubernetes technológiái}
Több Kubernetes technológia közül választhatunk, bepillantunk némelyikbe, hogy mire jó és miért ezt választjuk vagy nem választjuk.

\subsection{K8S}

A K8s a Kubernetes rövidítése ("K", majd 8 "ubernete", majd "s" betű). Azonban általában, amikor az emberek Kubernetesről vagy K8-ról beszélnek, akkor az eredeti upstream projektről beszélnek, amelyet a Google valóban rendkívül elérhető és skálázható platformként tervezett.

Tehát a Kubernetes minden alapfunkcióval, mely összességének tulajdonságai:
\begin{itemize}
	\item elválasztott Master és Worker node-ok, biztosítható az irányítás erőforrása
	\item etcd külön clusteren futtatható, biztosítható a terhelés kezelése
	\item ideális esetben külön bejáratú csomópontokkal rendelkezik, hogy azok könnyedén kezeljék a bejövő forgalmat, még akkor is, ha az alatta lévő csomópontok némelyike foglalt. \cite{k8svsk3s}
\end{itemize}
\subsection{K3S}
A K3S egy egyszerűsített változata a K8S-nek, melynek forrása 40MB bináris fájl, amely teljesen implementálja a Kubernetes API-t. Rengeteg extra driver-t kihagytak belőle, melyre alap esetben nincs szükség tesztrendszer vagy egyszerű klaszter esetén. Ezeket a kihagyott funkciókat egyébként később hozzá lehet illeszteni a rendszerhez add-onokkal. \cite{k8svsk3s}
\subsection{Kind}

A Kind egy Docker fölötti Kubernetes megvalósítás egy node-on. Egyszerű installálni, azonban nem a Kubernetes API-t használja.

\subsection{MiniKube}

A MiniKube az első Kubernetes technológia amely a fejlesztők ajánlása alapján a kezdőknek kipróbálásra a legalkalmasabb. Mivel egyszerű telepíteni, nincs nagy erőforrásigénye (2 vCPU/2GB RAM/20GB lemez). Egy gépre installálható, nem adható több node a klaszterhez. \cite{typesofkubernetes2}

\subsection{Miért K3S?}

A tanszéki klaszter természetesen egy teljes kialakított K8S, melyen az eredeti API használható és teljesértékű szolgáltatásokat lehet tesztelni a Kubernetes összes optimalizálásával. A Kind más API-t használ, így a telepítést leegyszerűsíteni, azonban nem összeegyeztethető egy Kind-os applikáció K8S megvalósításával. MiniKube már egyel jobb, azonban csak egy node-ot használ, ebben a projekben pedig fontos a hálózati tesztelés több node között. Így marad a K3S, amellyel a legjobban szimulálhatjuk a tanszéki K8S rendszert és a megvalósított applikáció is könnyen portolható.

\section{Konténerek átalakítása}

A felhasznált Docker konténereket néhány esetben változtatni kellett, ez csak a \emph{Dockerfile}-ra igaz, a forráskódok az eredeti esetben is működtek nem K3S rendszeren. Mindegyik konténerben volt egy kivétel, amely csak akkor engedte futtathatóvá tenni a konténert, ha az Docker rendszerben fut, ezt a \emph{[/.dockerenv} fájl létezésére vonatkozó feltétel. \\

\noindent
A PX4 szimuláció futtatószkripje (\emph{vke\_px4sim/docker-entrypoint.sh}) ugyan tartalmazza a beépített \emph{ROS\_IP} hirdetőcímet, amelyet a hálózati fejlesztés során többször átírtam, sikerült olyan végeredményre jutni, amelyben az eredeti konténer külső interfész IP-je maradhat. \\

\noindent
Az előkészített Roscore konténert a végleges verzióban nem használom, hiszen egyszerűbb volt az eredeti \emph{alpineros/alpine-ros:noetic-ros-core} publikus image-t megadni, amit a K8S API-ban tudtam testreszabni indított portszámmal és környezeti változókkal.

\section{Kubernetes virtualiztált telepítése Multipass VM-eken}

Egy több node-os klasztert valósítok meg virtualizáció fölött. Virtuális gépek létrehozására rengeteg program létezik, én a Multipass-t választottam. A Multipass egy letisztult VM menedzser Linux-ra, Windows-ra és MacOS-re, amellyel egy parancs indítani és törölni különálló VM-eket bármely CloudInit-et tartalmazó image-ről. Azért választottam ezt, mert könnyedén szkriptelhető a Klaszter törlése és felhúzása, mivel a fejlesztés során sokszor szeretném az alapbeállításról indítani a klasztert. \\

\noindent
Tehát írtam egy Bash scriptet, aminek segítségével létrehozok három VM-et és inicializálom rajtuk a K3S klasztert. Multipass VM-ek létrehozása Bash-ben egy-egy parancs (\ref{lst:mlaunch}. számú lista), melyek paramétereit természetesen egy config fájlból olvasok be, amiről még később szó lesz.
\begin{lstlisting}[caption={Multipass VM-ek létrehozása},label={lst:mlaunch}]
multipass launch --name master --cpus 2 --mem 2G --disk 2G
for w in "worker-1 worker-2"; do
	multipass launch --name $slave --cpus 2 --mem 2G --disk 30G
done
\end{lstlisting} 
\noindent
Létrehozás után a szkript kiadatja az Apt csomagkezelő program \emph{update és upgrade} parancsait, hogy a legfrissebb Ubuntu 20.04 kompatibilis csomagok legyenek a VM-eken. \\

\noindent
Frissítés után a master VM-en inicializálható a K3S master módban. A parancs eleje azt mutatja, hogy a master nevű VM-en hajtjük végre a "--" utáni parancsokat (\ref{lst:minit}. lista).
\begin{lstlisting}[caption={K3S Master inicializálása},label={lst:minit}]
multipass exec master -- /bin/bash -c "curl -sfL https://get.k3s.io | K3S_KUBECONFIG_MODE="644" sh -"
\end{lstlisting}
\noindent
Ha ez sikeres, akkor a worker node-okat is inicializálhatjuk, amihez két dologra lesz szükség, a master külső IP-jére, amin keresztül a másik VM tudja elérni, illetve a K3S egyedi tokenre. A master külső IP-jét a multipass egyik parancsából olvassuk ki, a grep programmal rákeresve a master névre, majd az IP cím formátumára reguláris kifejezéssel. A tokenhez szimplán kiíratunk egy fájlt a cat programmal. Ezekkel pedig a master-hez hasonló módon a K3S dokumentációban megadott curl programhívással inicializáljuk a slave-eket. (\ref{lst:initk3s}. lista)
\begin{lstlisting}[caption={K3S Slave-ek inicializálása},label={lst:initk3s}]
K3S_TOKEN=$(multipass exec $master sudo cat /var/lib/rancher/k3s/server/node-token)
MASTER_IP=$(multipass list | grep $master | grep -oE "\b([0-9]{1,3}\.){3}[0-9]{1,3}\b")

for slave in $slaves; do
	multipass exec $slave -- /bin/bash -c "curl -sfL https://get.k3s.io | K3S_TOKEN=${K3S_TOKEN} K3S_URL=https://${MASTER_IP}:6443 sh -"
done
\end{lstlisting}

\noindent
Sikerességet ellenőrizve a szkiptben még kiíratom a master-en a csatlakozott node-okat.
\begin{lstlisting}[caption={Node-ok lekérdezése}]
multipass exec $master kubectl get nodes
\end{lstlisting}

\section{Konténer registry, lokális és központi}
Docker-Compose esetén a konténer kollaborációs megvalósításhoz elég volt definiálni a könyvtárt, mely forrása és konfigurációja alapján meg kell építeni az image-et és a lokális Docker környezet eltárolta ezen image-eket, amit fel is tudott használni az adott környezetben. Ez természetesnek tűnt, azonban a Kubernetes alapvetően nem tartalmaz ilyen fejlesztéseket, csakis lefordított képfájlokat tud publikus vagy privát registry-ből letölteni.

...
\section{4 podos megvalósítás}

\section{Konténerek hálózata, service-deployment 1 podos megoldás}

\section{Load Balancer, NodePort, Ingress}
https://medium.com/google-cloud/kubernetes-nodeport-vs-loadbalancer-vs-ingress-when-should-i-use-what-922f010849e0

\section{ROS Port forwarding}
https://journals.sagepub.com/doi/pdf/10.1177/1729881417703355

\section{Kauzalitási probléma, deploy sorrend}

\section{N drónra K3S service és drónok deployolása}

\section{N drón irányítása K3S-ből}
